#!/usr/bin/env python3
"""
Full Control HPO Example - å®Œå…¨åƒæ•¸æ§åˆ¶ç¤ºä¾‹

é€™å€‹ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨FullControlHPOé€²è¡Œå®Œå…¨åƒæ•¸åŒ–çš„è¶…åƒæ•¸å„ªåŒ–ï¼Œ
åŒ…å«æ‰€æœ‰LLMç­–ç•¥å’ŒRLåƒæ•¸çš„ç´°ç²’åº¦æ§åˆ¶ã€‚
"""

import sys
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# Add MAT_HPO_LIB to path
sys.path.insert(0, '/home/vm230705/MAT-HPO-Library')

def example_fixed_alpha():
    """ç¤ºä¾‹1: å›ºå®šæ··åˆæ¯”ä¾‹ç­–ç•¥"""
    print("=" * 70)
    print("ç¤ºä¾‹1: Fixed Alpha Strategy - å›ºå®šæ··åˆæ¯”ä¾‹")
    print("=" * 70)

    from MAT_HPO_LIB import FullControlHPO

    # å‰µå»ºæ•¸æ“š
    X, y = make_classification(n_samples=400, n_features=15, n_classes=3,
                             n_informative=12, random_state=42)
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)

    print(f"æ•¸æ“šé›†: {X_train.shape[0]} è¨“ç·´æ¨£æœ¬, {X_val.shape[0]} é©—è­‰æ¨£æœ¬, {len(np.unique(y))} å€‹é¡åˆ¥")

    # å®Œå…¨æ§åˆ¶çš„HPO - å›ºå®šæ··åˆæ¯”ä¾‹
    optimizer = FullControlHPO(
        task_type="time_series_classification",
        max_trials=8,

        # LLM åƒæ•¸å®Œå…¨æ§åˆ¶
        llm_enabled=True,
        mixing_strategy="fixed_alpha",      # å›ºå®šæ··åˆç­–ç•¥
        alpha=0.4,                         # 40% LLM + 60% RL
        llm_model="llama3.2:3b",
        llm_cooldown_episodes=3,           # LLMå†·å»æœŸ3å€‹episode

        # RL åƒæ•¸å®Œå…¨æ§åˆ¶
        replay_buffer_size=500,            # ç¶“é©—å›æ”¾ç·©è¡å€
        learning_rate=0.002,               # RLå­¸ç¿’ç‡
        actor_lr=0.001,                    # Actorå­¸ç¿’ç‡
        critic_lr=0.003,                   # Criticå­¸ç¿’ç‡
        gamma=0.95,                        # æŠ˜æ‰£å› å­
        tau=0.005,                         # è»Ÿæ›´æ–°ä¿‚æ•¸
        hidden_dim=128,                    # éš±è—å±¤ç¶­åº¦

        # å…¶ä»–åƒæ•¸
        seed=42,
        verbose=True,
        output_dir="./full_control_fixed_alpha_results"
    )

    print("\\nğŸ¯ ä½¿ç”¨å›ºå®šæ··åˆæ¯”ä¾‹ (40% LLM + 60% RL)")
    results = optimizer.optimize(X_train, y_train, X_val, y_val)

    print(f"\\nğŸ“Š æœ€ä½³æ€§èƒ½:")
    for metric, value in results['best_performance'].items():
        print(f"   {metric}: {value:.4f}")

    return results

def example_adaptive_strategy():
    """ç¤ºä¾‹2: è‡ªé©æ‡‰ç­–ç•¥ - ç›£æ§æ€§èƒ½æ–œç‡"""
    print("\\n" + "=" * 70)
    print("ç¤ºä¾‹2: Adaptive Strategy - æ€§èƒ½æ–œç‡ç›£æ§")
    print("=" * 70)

    from MAT_HPO_LIB import FullControlHPO

    # å‰µå»ºæ›´è¤‡é›œçš„æ•¸æ“š
    X, y = make_classification(n_samples=600, n_features=20, n_classes=4,
                             n_informative=16, random_state=123)
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123)

    print(f"æ•¸æ“šé›†: {X_train.shape[0]} è¨“ç·´æ¨£æœ¬, {X_val.shape[0]} é©—è­‰æ¨£æœ¬")

    # è‡ªé©æ‡‰ç­–ç•¥ - ç›£æ§RLæ€§èƒ½æ–œç‡
    optimizer = FullControlHPO(
        task_type="ecg_classification",
        max_trials=10,

        # LLM è‡ªé©æ‡‰åƒæ•¸
        llm_enabled=True,
        mixing_strategy="adaptive",         # è‡ªé©æ‡‰ç­–ç•¥
        slope_threshold=0.005,              # æ–œç‡é–¾å€¼ - æ›´æ•æ„Ÿ
        min_episodes_before_llm=3,          # æœ€å°‘3å€‹episodeæ‰æª¢æŸ¥æ–œç‡
        llm_cooldown_episodes=4,            # å†·å»æœŸ4å€‹episode

        # RL åƒæ•¸èª¿å„ª
        replay_buffer_size=800,
        learning_rate=0.0015,
        batch_size=32,                      # è¼ƒå°çš„æ‰¹æ¬¡
        gamma=0.98,
        tau=0.002,

        # å…¶ä»–åƒæ•¸
        seed=123,
        verbose=True,
        output_dir="./full_control_adaptive_results"
    )

    print(f"\\nğŸ¯ ä½¿ç”¨è‡ªé©æ‡‰ç­–ç•¥ (æ–œç‡é–¾å€¼: {optimizer.slope_threshold})")
    print(f"   ç•¶RLæ€§èƒ½æ–œç‡ < {optimizer.slope_threshold} æ™‚ï¼Œå¢åŠ LLMä½¿ç”¨")
    results = optimizer.optimize(X_train, y_train, X_val, y_val)

    stats = optimizer.get_optimization_stats()
    print(f"\\nğŸ“ˆ å„ªåŒ–çµ±è¨ˆ:")
    print(f"   ç¸½è€—æ™‚: {stats['optimization_time']:.2f} ç§’")
    print(f"   è©¦é©—å®Œæˆ: {stats['trials_completed']}")

    return results

def example_adaptive_slope_monitoring():
    """ç¤ºä¾‹3: Adaptiveç­–ç•¥ - åŸºæ–¼è«–æ–‡arXiv:2507.13712çš„RLæ€§èƒ½æ–œç‡ç›£æ§"""
    print("\\n" + "=" * 70)
    print("ç¤ºä¾‹3: Adaptive Strategy - åŸºæ–¼è«–æ–‡çš„RLæ€§èƒ½æ–œç‡ç›£æ§")
    print("=" * 70)

    from MAT_HPO_LIB import FullControlHPO

    # å‰µå»ºæ™‚é–“åºåˆ—æ•¸æ“š
    np.random.seed(456)
    n_samples, seq_length = 300, 80
    X = np.random.randn(n_samples, seq_length, 1)

    # æ·»åŠ æ¨¡å¼
    for i in range(n_samples):
        if i % 3 == 0:  # é¡åˆ¥0: æ­£å¼¦æ³¢
            X[i, :, 0] += np.sin(np.linspace(0, 4*np.pi, seq_length))
        elif i % 3 == 1:  # é¡åˆ¥1: é¤˜å¼¦æ³¢
            X[i, :, 0] += np.cos(np.linspace(0, 4*np.pi, seq_length))
        else:  # é¡åˆ¥2: é‹¸é½’æ³¢
            X[i, :, 0] += np.linspace(-1, 1, seq_length)

    y = np.array([i % 3 for i in range(n_samples)])
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=456)

    print(f"æ™‚é–“åºåˆ—æ•¸æ“š: {X_train.shape}")

    # LLaPipeç­–ç•¥ - åŸºæ–¼è«–æ–‡çš„å¯¦ç¾
    optimizer = FullControlHPO(
        task_type="time_series_classification",
        max_trials=12,

        # Adaptive ç‰¹å®šåƒæ•¸
        llm_enabled=True,
        mixing_strategy="adaptive",         # è‡ªé©æ‡‰ç­–ç•¥
        slope_threshold=0.01,               # RLæ€§èƒ½æ–œç‡é–¾å€¼ (è«–æ–‡å»ºè­°)
        min_episodes_before_llm=5,          # é–‹å§‹ç›£æ§å‰çš„æœ€å°‘episodeæ•¸

        # é‡å°æ™‚é–“åºåˆ—çš„RLåƒæ•¸
        replay_buffer_size=1000,
        learning_rate=0.001,
        actor_lr=0.0008,
        critic_lr=0.002,
        hidden_dim=256,                     # è¼ƒå¤§çš„éš±è—å±¤

        # è¨­å‚™å’Œè¼¸å‡º
        device="auto",
        seed=456,
        verbose=True,
        output_dir="./full_control_llmpipe_results"
    )

    print(f"\\nğŸ¯ ä½¿ç”¨Adaptiveç­–ç•¥ (åŸºæ–¼è«–æ–‡arXiv:2507.13712)")
    print(f"   ç›£æ§RLå­¸ç¿’æ›²ç·šæ–œç‡ï¼Œç•¶ < {optimizer.slope_threshold} æ™‚è§¸ç™¼LLM")
    results = optimizer.optimize(X_train, y_train, X_val, y_val)

    # ç²å–æœ€ä½³é…ç½®
    best_config = optimizer.get_best_config()
    print(f"\\nâš™ï¸ æœ€ä½³è¶…åƒæ•¸é…ç½®:")
    for param, value in best_config.items():
        if isinstance(value, float):
            print(f"   {param}: {value:.6f}")
        else:
            print(f"   {param}: {value}")

    return results

def example_custom_hyperparameter_space():
    """ç¤ºä¾‹4: è‡ªå®šç¾©è¶…åƒæ•¸ç©ºé–“"""
    print("\\n" + "=" * 70)
    print("ç¤ºä¾‹4: Custom Hyperparameter Space - è‡ªå®šç¾©æœç´¢ç©ºé–“")
    print("=" * 70)

    from MAT_HPO_LIB import FullControlHPO, HyperparameterSpace

    # å‰µå»ºæ•¸æ“š
    X, y = make_classification(n_samples=400, n_features=12, n_classes=2,
                             n_informative=10, random_state=789)
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=789)

    # å®šç¾©è‡ªå®šç¾©è¶…åƒæ•¸ç©ºé–“
    custom_space = HyperparameterSpace()

    # Agent 0: æ¨¡å‹æ¶æ§‹åƒæ•¸
    custom_space.add_discrete('hidden_size', [64, 128, 256, 512], agent=0)
    custom_space.add_continuous('dropout', 0.1, 0.7, agent=0)
    custom_space.add_discrete('num_layers', [2, 3, 4], agent=0)

    # Agent 1: è¨“ç·´åƒæ•¸
    custom_space.add_continuous('learning_rate', 0.0001, 0.05, agent=1)
    custom_space.add_discrete('batch_size', [8, 16, 32, 64, 128], agent=1)
    custom_space.add_continuous('weight_decay', 1e-6, 1e-2, agent=1)

    # Agent 2: å„ªåŒ–åƒæ•¸
    custom_space.add_continuous('momentum', 0.8, 0.99, agent=2)
    custom_space.add_discrete('optimizer_type', ['adam', 'sgd', 'rmsprop'], agent=2)

    print(f"ğŸ”§ è‡ªå®šç¾©è¶…åƒæ•¸ç©ºé–“:")
    print(f"   Agent 0 (æ¶æ§‹): hidden_size, dropout, num_layers")
    print(f"   Agent 1 (è¨“ç·´): learning_rate, batch_size, weight_decay")
    print(f"   Agent 2 (å„ªåŒ–): momentum, optimizer_type")

    # ä½¿ç”¨æ··åˆç­–ç•¥
    optimizer = FullControlHPO(
        task_type="classification",
        max_trials=10,

        # æ··åˆç­–ç•¥åƒæ•¸
        llm_enabled=True,
        mixing_strategy="hybrid",           # æ··åˆç­–ç•¥
        alpha=0.25,                        # åŸºç¤æ··åˆæ¯”ä¾‹
        slope_threshold=0.008,

        # ç²¾ç´°èª¿æ•´çš„RLåƒæ•¸
        replay_buffer_size=600,
        learning_rate=0.0012,
        gamma=0.97,
        tau=0.003,

        seed=789,
        verbose=True,
        output_dir="./full_control_custom_space_results"
    )

    print(f"\\nğŸ¯ ä½¿ç”¨æ··åˆç­–ç•¥ + è‡ªå®šç¾©è¶…åƒæ•¸ç©ºé–“")
    results = optimizer.optimize(X_train, y_train, X_val, y_val,
                               custom_space=custom_space)

    # å±•ç¤ºæœ€ä½³é…ç½®
    best_config = optimizer.get_best_config()
    print(f"\\nğŸ† æœ€ä½³é…ç½® (è‡ªå®šç¾©ç©ºé–“):")
    for param, value in best_config.items():
        print(f"   {param}: {value}")

    return results

def example_convenience_function():
    """ç¤ºä¾‹5: ä¾¿åˆ©å‡½æ•¸ä½¿ç”¨"""
    print("\\n" + "=" * 70)
    print("ç¤ºä¾‹5: Convenience Function - ä¾¿åˆ©å‡½æ•¸")
    print("=" * 70)

    from MAT_HPO_LIB.full_control_hpo import full_control_optimize

    # å‰µå»ºç°¡å–®æ•¸æ“š
    X, y = make_classification(n_samples=200, n_features=8, n_classes=2,
                             n_informative=6, random_state=999)
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=999)

    print(f"æ•¸æ“šé›†: {X_train.shape[0]} è¨“ç·´æ¨£æœ¬")

    # ä½¿ç”¨ä¾¿åˆ©å‡½æ•¸
    print(f"\\nğŸš€ ä½¿ç”¨ä¾¿åˆ©å‡½æ•¸é€²è¡Œä¸€è¡Œå¼å„ªåŒ–")
    best_config = full_control_optimize(
        X_train, y_train, X_val, y_val,
        task_type="classification",
        max_trials=6,
        llm_strategy="adaptive",
        alpha=0.35,
        slope_threshold=0.012,
        learning_rate=0.0018,
        replay_buffer_size=400,
        verbose=True
    )

    print(f"\\nğŸ¯ æœ€ä½³é…ç½® (ä¾¿åˆ©å‡½æ•¸):")
    for param, value in best_config.items():
        if isinstance(value, float):
            print(f"   {param}: {value:.6f}")
        else:
            print(f"   {param}: {value}")

    return best_config

def main():
    """é‹è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("Full Control HPO å®Œæ•´ç¤ºä¾‹")
    print("=" * 70)
    print("é€™äº›ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨FullControlHPOé€²è¡Œå®Œå…¨åƒæ•¸åŒ–çš„è¶…åƒæ•¸å„ªåŒ–")
    print("åŒ…å«æ‰€æœ‰LLMç­–ç•¥å’ŒRLåƒæ•¸çš„ç´°ç²’åº¦æ§åˆ¶")
    print()

    try:
        # é‹è¡Œæ‰€æœ‰ç¤ºä¾‹
        print("ğŸ¯ é–‹å§‹é‹è¡Œå®Œå…¨æ§åˆ¶HPOç¤ºä¾‹...")

        result1 = example_fixed_alpha()
        result2 = example_adaptive_strategy()
        result3 = example_adaptive_slope_monitoring()
        result4 = example_custom_hyperparameter_space()
        result5 = example_convenience_function()

        print("\\n" + "ğŸ‰" * 25)
        print("æ‰€æœ‰Full Control HPOç¤ºä¾‹æˆåŠŸå®Œæˆ!")
        print("ğŸ‰" * 25)

        # ç¸½çµå°æ¯”
        print("\\nğŸ“Š ç­–ç•¥æ•ˆæœå°æ¯”:")
        print(f"Fixed Alpha:     F1={result1['best_performance'].get('f1', 0):.4f}")
        print(f"Adaptive Basic:  F1={result2['best_performance'].get('f1', 0):.4f}")
        print(f"Adaptive Slope:  F1={result3['best_performance'].get('f1', 0):.4f}")
        print(f"Custom Space:    F1={result4['best_performance'].get('f1', 0):.4f}")

    except KeyboardInterrupt:
        print("\\nâŒ ç¤ºä¾‹è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\\nâŒ é‹è¡Œç¤ºä¾‹æ™‚å‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()