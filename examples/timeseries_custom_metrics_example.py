#!/usr/bin/env python3
"""
æ™‚é–“åºåˆ—é æ¸¬çš„MAT-HPOé€šç”¨æ¥å£ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨MAT-HPO-Libraryçš„é€šç”¨æ¥å£ä¾†ï¼š
1. è‡ªè¨‚metricsï¼ˆå¦‚MASE, SMAPE, MAE, RMSEï¼‰
2. è‡ªè¨‚reward function
3. è‡ªè¨‚loggerçš„metricsæå–å™¨
"""

import sys
sys.path.append('/home/vm230705/research/MAT-HPO-Library')
sys.path.append('/home/vm230705/research/nnts')

from MAT_HPO_LIB import MAT_HPO_Optimizer, BaseEnvironment, HyperparameterSpace
from MAT_HPO_LIB.utils import DefaultConfigs
from MAT_HPO_LIB.utils.logger import HPOLogger
import numpy as np

# ============================================================================
# æ­¥é©Ÿ 1: å®šç¾©è‡ªè¨‚çš„metricsæå–å™¨
# ============================================================================

def timeseries_metrics_extractor(hyperparams: dict) -> dict:
    """
    å¾hyperparamsä¸­æå–æ‰€æœ‰æ™‚é–“åºåˆ—ç›¸é—œçš„åŸå§‹æŒ‡æ¨™
    
    é€™å€‹å‡½æ•¸å®šç¾©äº†è¦è¨˜éŒ„å“ªäº›æŒ‡æ¨™ï¼Œä»¥åŠå¦‚ä½•å¾hyperparamsä¸­æå–å®ƒå€‘
    
    Args:
        hyperparams: åŒ…å«æ‰€æœ‰åƒæ•¸å’ŒæŒ‡æ¨™çš„å­—å…¸
        
    Returns:
        åŒ…å«æ‰€æœ‰è¦è¨˜éŒ„çš„åŸå§‹æŒ‡æ¨™çš„å­—å…¸
    """
    metrics = {}
    
    # æ ¸å¿ƒæ™‚é–“åºåˆ—æŒ‡æ¨™
    if 'train_loss' in hyperparams:
        metrics['train_loss'] = float(hyperparams['train_loss'])
    if 'val_loss' in hyperparams:
        metrics['val_loss'] = float(hyperparams['val_loss'])
    if 'overfitting_ratio' in hyperparams:
        metrics['overfitting_ratio'] = float(hyperparams['overfitting_ratio'])
    
    # é æ¸¬èª¤å·®æŒ‡æ¨™
    if 'mase' in hyperparams:
        metrics['mase'] = float(hyperparams['mase'])
    if 'mae' in hyperparams:
        metrics['mae'] = float(hyperparams.get('original_mae', hyperparams['mae']))
    if 'rmse' in hyperparams:
        metrics['rmse'] = float(hyperparams.get('original_rmse', hyperparams['rmse']))
    if 'smape' in hyperparams:
        metrics['smape'] = float(hyperparams.get('original_smape', hyperparams['smape']))
    if 'mse' in hyperparams:
        metrics['mse'] = float(hyperparams['mse'])
    if 'mape' in hyperparams:
        metrics['mape'] = float(hyperparams['mape'])
    if 'msmape' in hyperparams:
        metrics['msmape'] = float(hyperparams['msmape'])
    
    return metrics


# ============================================================================
# æ­¥é©Ÿ 2: å®šç¾©è‡ªè¨‚çš„rewardå‡½æ•¸
# ============================================================================

def timeseries_reward_function(metrics: dict) -> float:
    """
    åŸºæ–¼è¨“ç·´æå¤±è¨ˆç®—rewardï¼ˆé¿å…data leakageï¼‰
    
    ä½¿ç”¨è¨“ç·´æå¤±è€Œéæ¸¬è©¦é›†æŒ‡æ¨™ï¼Œç¢ºä¿ç¬¦åˆbenchmarkè¦æ±‚
    
    Args:
        metrics: åŒ…å«æ‰€æœ‰è©•ä¼°æŒ‡æ¨™çš„å­—å…¸
        
    Returns:
        rewardå€¼ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
    """
    train_loss = metrics.get('train_loss', 1.0)
    
    # é˜²æ­¢ç„¡æ•ˆå€¼
    if np.isnan(train_loss) or np.isinf(train_loss) or train_loss <= 0:
        train_loss = 1.0
    
    # å°‡è¨“ç·´æå¤±è½‰æ›ç‚ºrewardï¼ˆè¶Šå°çš„losså¾—åˆ°è¶Šé«˜çš„rewardï¼‰
    # ä½¿ç”¨è² å°æ•¸è½‰æ›
    pseudo_mase = -np.log(max(train_loss, 1e-6))
    pseudo_mase = max(0.1, min(10.0, pseudo_mase))
    
    # è½‰æ›ç‚º0-1ç¯„åœçš„reward
    if pseudo_mase <= 0.5:
        reward = 0.8 - 0.15 * (np.log(pseudo_mase + 0.1) + 2.3)
    elif pseudo_mase <= 1.0:
        normalized = (pseudo_mase - 0.5) / 0.5
        reward = 0.72 - 0.27 * normalized
    elif pseudo_mase <= 2.0:
        normalized = (pseudo_mase - 1.0) / 1.0
        reward = 0.45 * np.exp(-normalized * 0.8)
    else:
        reward = 0.2 * np.exp(-(pseudo_mase - 2.0) * 0.3)
    
    return max(0.05, min(0.9, reward))


# ============================================================================
# æ­¥é©Ÿ 3: ä½¿ç”¨é€šç”¨æ¥å£å‰µå»ºç’°å¢ƒ
# ============================================================================

class TimeSeriesEnvironmentWithCustomMetrics(BaseEnvironment):
    """
    ä½¿ç”¨é€šç”¨æ¥å£çš„æ™‚é–“åºåˆ—ç’°å¢ƒ
    
    ä¸éœ€è¦ä¿®æ”¹MAT-HPO-Libraryçš„ä»£ç¢¼ï¼Œç›´æ¥é€šéåƒæ•¸é…ç½®
    """
    
    def __init__(self, model_name: str, dataset_name: str, **kwargs):
        # å®šç¾©è¦è¿½è¹¤çš„custom metrics
        custom_metrics = ['train_loss', 'val_loss', 'mase', 'smape', 'mae', 'rmse', 'overfitting_ratio']
        
        # å®šç¾©metricåç¨±æ˜ å°„ï¼ˆç”¨æ–¼é¡¯ç¤ºï¼‰
        metric_names_mapping = {
            'f1': 'SMAPE',
            'auc': 'MAE', 
            'gmean': 'RMSE'
        }
        
        # ä½¿ç”¨è‡ªè¨‚rewardå‡½æ•¸
        super().__init__(
            name=f"TimeSeries-{model_name}-{dataset_name}",
            custom_metrics=custom_metrics,
            metric_names_mapping=metric_names_mapping,
            reward_function=timeseries_reward_function,
            **kwargs
        )
        
        self.model_name = model_name
        self.dataset_name = dataset_name
    
    def load_data(self):
        """è¼‰å…¥æ•¸æ“š"""
        # å¯¦ä½œæ•¸æ“šè¼‰å…¥é‚è¼¯
        pass
    
    def create_model(self, hyperparams):
        """å‰µå»ºæ¨¡å‹"""
        # å¯¦ä½œæ¨¡å‹å‰µå»ºé‚è¼¯
        pass
    
    def train_evaluate(self, model, hyperparams):
        """è¨“ç·´å’Œè©•ä¼°"""
        # è¨“ç·´æ¨¡å‹...
        
        # è¿”å›æ‰€æœ‰åŸå§‹æŒ‡æ¨™
        return {
            'train_loss': 331.72,
            'val_loss': 346.51,
            'overfitting_ratio': 1.045,
            'mase': 2.304,
            'smape': 0.0618,
            'mae': 632.53,
            'rmse': 809.25,
            'mse': 654889.81,
            # è½‰æ›å¾Œçš„å€¼ï¼ˆçµ¦MAT-HPOå„ªåŒ–ç”¨ï¼‰
            'f1': 0.7691,   # SMAPEè½‰æ›å¾Œ
            'auc': 0.1675,  # MAEè½‰æ›å¾Œ
            'gmean': 0.1000, # RMSEè½‰æ›å¾Œ
            # ä¿å­˜åŸå§‹å€¼
            'original_smape': 0.0618,
            'original_mae': 632.53,
            'original_rmse': 809.25
        }
    
    def compute_reward(self, metrics):
        """è¨ˆç®—reward"""
        # å¦‚æœæä¾›äº†custom_reward_functionï¼Œä½¿ç”¨å®ƒ
        if hasattr(self, 'custom_reward_function') and self.custom_reward_function:
            return self.custom_reward_function(metrics)
        else:
            # é»˜èªä½¿ç”¨train_loss
            return timeseries_reward_function(metrics)


# ============================================================================
# æ­¥é©Ÿ 4: ä½¿ç”¨é€šç”¨æ¥å£å‰µå»ºoptimizerå’Œlogger
# ============================================================================

def main():
    """ä¸»å‡½æ•¸ï¼šå±•ç¤ºå¦‚ä½•ä½¿ç”¨é€šç”¨æ¥å£"""
    
    # å‰µå»ºç’°å¢ƒï¼ˆä½¿ç”¨custom metricså’Œrewardï¼‰
    env = TimeSeriesEnvironmentWithCustomMetrics(
        model_name="dlinear",
        dataset_name="us_births"
    )
    
    # å‰µå»ºhyperparameter space
    space = HyperparameterSpace()
    space.add_continuous('learning_rate', 1e-5, 1e-2, agent=0)
    space.add_discrete('batch_size', [8, 16, 32, 64], agent=0)
    
    # å‰µå»ºé…ç½®
    config = DefaultConfigs.standard()
    config.max_steps = 5
    
    # å‰µå»ºloggerï¼ˆä½¿ç”¨custom metrics extractorï¼‰
    logger = HPOLogger(
        output_dir='./timeseries_custom_test',
        metric_names={'f1': 'SMAPE', 'auc': 'MAE', 'gmean': 'RMSE'},
        custom_metrics=['train_loss', 'val_loss', 'mase', 'smape', 'mae', 'rmse'],
        metrics_extractor=timeseries_metrics_extractor
    )
    
    # å‰µå»ºoptimizer
    optimizer = MAT_HPO_Optimizer(env, space, config)
    optimizer.logger = logger  # ä½¿ç”¨è‡ªè¨‚logger
    
    # é‹è¡Œå„ªåŒ–
    results = optimizer.optimize()
    
    print("\nâœ… å„ªåŒ–å®Œæˆï¼")
    print(f"æœ€ä½³reward: {results['best_performance']['reward']:.4f}")
    print(f"æœ€ä½³è¶…åƒæ•¸: {results['best_hyperparameters']}")


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¯ MAT-HPO é€šç”¨æ¥å£ç¤ºä¾‹ï¼šæ™‚é–“åºåˆ—é æ¸¬")
    print("=" * 60)
    print("\nğŸ“ å±•ç¤ºåŠŸèƒ½ï¼š")
    print("  1. è‡ªè¨‚metricsåˆ—è¡¨")
    print("  2. è‡ªè¨‚metricsæå–å™¨")
    print("  3. è‡ªè¨‚rewardå‡½æ•¸")
    print("  4. è‡ªè¨‚metricåç¨±æ˜ å°„")
    print("\n" + "=" * 60 + "\n")
    
    main()


