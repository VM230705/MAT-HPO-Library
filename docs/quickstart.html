<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quick Start Guide - MAT-HPO Library</title>
    <meta name="description" content="Get started with MAT-HPO Library in minutes. Learn the basics and run your first hyperparameter optimization.">
    <link rel="stylesheet" href="css/style.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ü§ñ</text></svg>">
</head>
<body>
    <button class="mobile-toggle">‚ò∞</button>
    
    <div class="container">
        <!-- Sidebar Navigation (same as index.html) -->
        <nav class="sidebar">
            <div class="sidebar-header">
                <a href="index.html" class="logo">
                    <div class="logo-icon">M</div>
                    <div class="logo-text">
                        <h1>MAT-HPO</h1>
                        <p>Multi-Agent Transformer HPO</p>
                    </div>
                </a>
                <div style="margin-top: 1rem;">
                    <span class="version-badge">v1.0.0</span>
                </div>
            </div>
            
            <ul class="nav-menu">
                <li class="nav-item">
                    <div class="nav-section">Getting Started</div>
                </li>
                <li class="nav-item">
                    <a href="index.html" class="nav-link">Home</a>
                </li>
                <li class="nav-item">
                    <a href="installation.html" class="nav-link">Installation</a>
                </li>
                <li class="nav-item">
                    <a href="quickstart.html" class="nav-link active">Quick Start</a>
                </li>
                
                <li class="nav-item">
                    <div class="nav-section">Core Concepts</div>
                </li>
                <li class="nav-item">
                    <a href="architecture.html" class="nav-link">Architecture</a>
                </li>
                <li class="nav-item">
                    <a href="multi-agent.html" class="nav-link">Multi-Agent System</a>
                </li>
                <li class="nav-item">
                    <a href="environments.html" class="nav-link">Environments</a>
                </li>
                
                <li class="nav-item">
                    <div class="nav-section">API Reference</div>
                </li>
                <li class="nav-item">
                    <a href="api/base-environment.html" class="nav-link">BaseEnvironment</a>
                </li>
                <li class="nav-item">
                    <a href="api/hyperparameter-space.html" class="nav-link">HyperparameterSpace</a>
                </li>
                <li class="nav-item">
                    <a href="api/optimizer.html" class="nav-link">MAT_HPO_Optimizer</a>
                </li>
                <li class="nav-item">
                    <a href="api/config.html" class="nav-link">Configuration</a>
                </li>
                
                <li class="nav-item">
                    <div class="nav-section">Examples & Tutorials</div>
                </li>
                <li class="nav-item">
                    <a href="examples/simple.html" class="nav-link">Simple Example</a>
                </li>
                <li class="nav-item">
                    <a href="examples/image-classification.html" class="nav-link">Image Classification</a>
                </li>
                <li class="nav-item">
                    <a href="examples/nlp.html" class="nav-link">NLP Tasks</a>
                </li>
                <li class="nav-item">
                    <a href="examples/time-series.html" class="nav-link">Time Series</a>
                </li>
            </ul>
        </nav>
        
        <!-- Main Content -->
        <main class="content">
            <div class="content-header">
                <ol class="breadcrumb">
                    <li><a href="index.html">Home</a></li>
                    <li>Quick Start</li>
                </ol>
            </div>
            
            <div class="main-content">
                <h1>üöÄ Quick Start Guide</h1>
                <p class="lead">Get up and running with MAT-HPO in minutes. This guide will walk you through your first hyperparameter optimization using the MAT-HPO library.</p>
                
                <div id="table-of-contents">
                    <h3>Contents</h3>
                    <!-- TOC will be generated by JavaScript -->
                </div>
                
                <!-- Prerequisites -->
                <section>
                    <h2>üìã Prerequisites</h2>
                    <div class="alert alert-info">
                        <strong>Before you begin:</strong> Make sure you have Python 3.8+ and basic familiarity with PyTorch and scikit-learn.
                    </div>
                    
                    <h3>System Requirements</h3>
                    <ul>
                        <li><strong>Python:</strong> 3.8 or higher</li>
                        <li><strong>Memory:</strong> At least 4GB RAM (8GB+ recommended)</li>
                        <li><strong>GPU:</strong> Optional but recommended for large-scale optimization</li>
                        <li><strong>Disk Space:</strong> ~500MB for library and dependencies</li>
                    </ul>
                    
                    <h3>Dependencies</h3>
                    <pre><code class="language-txt">torch>=1.9.0
numpy>=1.19.0
scikit-learn>=0.24.0
tqdm>=4.60.0</code></pre>
                </section>
                
                <!-- Installation -->
                <section>
                    <h2>üì¶ Installation</h2>
                    
                    <h3>Option 1: Install from PyPI (Recommended)</h3>
                    <pre><code class="language-bash">pip install mat-hpo-lib</code></pre>
                    
                    <h3>Option 2: Install from Source</h3>
                    <pre><code class="language-bash"># Clone the repository
git clone https://github.com/your-org/MAT_HPO_LIB.git
cd MAT_HPO_LIB

# Install in development mode
pip install -e .</code></pre>
                    
                    <h3>Verify Installation</h3>
                    <pre><code class="language-python">from MAT_HPO_LIB import MAT_HPO_Optimizer, BaseEnvironment, HyperparameterSpace
print("‚úÖ MAT-HPO Library successfully imported!")</code></pre>
                </section>
                
                <!-- 30-Second Example -->
                <section>
                    <h2>‚ö° 30-Second Example</h2>
                    <p>Here's the simplest possible example to get you started:</p>
                    
                    <pre><code class="language-python">from MAT_HPO_LIB import *
from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
import numpy as np

# Quick synthetic dataset
X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)

class SimpleRFEnvironment(BaseEnvironment):
    def __init__(self):
        super().__init__(name="SimpleRF")
        self.X, self.y = X, y
    
    def load_data(self):
        return {"loaded": True}
    
    def create_model(self, hyperparams):
        return RandomForestClassifier(
            n_estimators=hyperparams['n_estimators'],
            max_depth=hyperparams['max_depth'],
            random_state=42
        )
    
    def train_evaluate(self, model, hyperparams):
        # Use cross-validation for robust evaluation
        scores = cross_val_score(model, self.X, self.y, cv=5, scoring='f1')
        return {'f1': scores.mean(), 'f1_std': scores.std()}
    
    def compute_reward(self, metrics):
        return metrics['f1']

# Define search space
space = HyperparameterSpace(
    agent0_params=[],
    agent1_params=['n_estimators', 'max_depth'],
    agent2_params=[],
    bounds={
        'n_estimators': (10, 100),
        'max_depth': (3, 20)
    },
    param_types={
        'n_estimators': int,
        'max_depth': int
    }
)

# Run optimization
environment = SimpleRFEnvironment()
optimizer = MAT_HPO_Optimizer(environment, space, DefaultConfigs.quick_test())
results = optimizer.optimize()

print(f"üéâ Best F1 Score: {results['best_performance']['f1']:.4f}")
print(f"üéØ Best Parameters: {results['best_hyperparameters']}")</code></pre>
                </section>
                
                <!-- Core Concepts -->
                <section>
                    <h2>üß† Core Concepts</h2>
                    
                    <h3>The Four Essential Components</h3>
                    <div class="grid grid-2">
                        <div class="card">
                            <h4>1. BaseEnvironment</h4>
                            <p>Your optimization problem wrapper. Inherit from this class and implement four methods:</p>
                            <ul>
                                <li><code>load_data()</code> - Load your dataset</li>
                                <li><code>create_model()</code> - Create model with hyperparams</li>
                                <li><code>train_evaluate()</code> - Train and evaluate</li>
                                <li><code>compute_reward()</code> - Convert metrics to reward</li>
                            </ul>
                        </div>
                        
                        <div class="card">
                            <h4>2. HyperparameterSpace</h4>
                            <p>Defines what parameters to optimize and their constraints:</p>
                            <ul>
                                <li><code>bounds</code> - Parameter ranges</li>
                                <li><code>param_types</code> - Data types (int, float, str)</li>
                                <li><code>agent_params</code> - Which agent handles each parameter</li>
                            </ul>
                        </div>
                        
                        <div class="card">
                            <h4>3. Configuration</h4>
                            <p>Optimization settings and hyperparameters:</p>
                            <ul>
                                <li><code>max_steps</code> - How many evaluations to run</li>
                                <li><code>use_cuda</code> - Enable GPU acceleration</li>
                                <li><code>early_stop_patience</code> - When to stop early</li>
                            </ul>
                        </div>
                        
                        <div class="card">
                            <h4>4. MAT_HPO_Optimizer</h4>
                            <p>The main optimization engine that:</p>
                            <ul>
                                <li>Manages the three specialized agents</li>
                                <li>Coordinates the search process</li>
                                <li>Tracks results and handles checkpointing</li>
                            </ul>
                        </div>
                    </div>
                    
                    <h3>Multi-Agent Architecture</h3>
                    <div class="alert alert-info">
                        <strong>Key Insight:</strong> MAT-HPO uses three specialized agents that focus on different types of hyperparameters, enabling more efficient parallel search.
                    </div>
                    
                    <ul>
                        <li><strong>Agent 0 (Problem-Specific):</strong> Class weights, regularization, domain-specific parameters</li>
                        <li><strong>Agent 1 (Architecture):</strong> Model structure, hidden sizes, number of layers</li>
                        <li><strong>Agent 2 (Training):</strong> Learning rates, batch sizes, optimization settings</li>
                    </ul>
                </section>
                
                <!-- Step-by-Step Tutorial -->
                <section>
                    <h2>üë®‚Äçüíª Step-by-Step Tutorial</h2>
                    <p>Let's build a complete neural network optimization example from scratch:</p>
                    
                    <h3>Step 1: Import Dependencies</h3>
                    <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
import numpy as np

from MAT_HPO_LIB import (
    BaseEnvironment, 
    HyperparameterSpace, 
    MAT_HPO_Optimizer,
    DefaultConfigs
)</code></pre>
                    
                    <h3>Step 2: Define Your Neural Network</h3>
                    <pre><code class="language-python">class SimpleNN(nn.Module):
    def __init__(self, input_dim, hidden_size, num_classes, dropout_rate=0.2):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_size // 2, num_classes)
        )
    
    def forward(self, x):
        return self.network(x)</code></pre>
                    
                    <h3>Step 3: Create Your Environment</h3>
                    <pre><code class="language-python">class NeuralNetEnvironment(BaseEnvironment):
    def __init__(self, max_epochs=20):
        super().__init__(name="NeuralNetOptimization")
        self.max_epochs = max_epochs
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
    def load_data(self):
        # Create synthetic dataset
        X, y = make_classification(
            n_samples=2000, 
            n_features=50, 
            n_classes=3, 
            n_informative=30,
            random_state=42
        )
        
        # Split data
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Convert to tensors
        self.X_train = torch.FloatTensor(X_train).to(self.device)
        self.X_val = torch.FloatTensor(X_val).to(self.device)
        self.y_train = torch.LongTensor(y_train).to(self.device)
        self.y_val = torch.LongTensor(y_val).to(self.device)
        
        self.input_dim = X.shape[1]
        self.num_classes = len(np.unique(y))
        
        return {
            "train_samples": len(X_train),
            "val_samples": len(X_val),
            "features": self.input_dim,
            "classes": self.num_classes
        }
    
    def create_model(self, hyperparams):
        model = SimpleNN(
            input_dim=self.input_dim,
            hidden_size=hyperparams['hidden_size'],
            num_classes=self.num_classes,
            dropout_rate=hyperparams.get('dropout_rate', 0.2)
        )
        return model.to(self.device)
    
    def train_evaluate(self, model, hyperparams):
        # Setup training
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(
            model.parameters(), 
            lr=hyperparams['learning_rate'],
            weight_decay=hyperparams.get('weight_decay', 1e-4)
        )
        
        # Create data loaders
        train_dataset = TensorDataset(self.X_train, self.y_train)
        train_loader = DataLoader(
            train_dataset, 
            batch_size=hyperparams['batch_size'], 
            shuffle=True
        )
        
        # Training loop
        model.train()
        for epoch in range(self.max_epochs):
            epoch_loss = 0
            for batch_X, batch_y in train_loader:
                optimizer.zero_grad()
                outputs = model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
            
            # Early stopping check
            avg_loss = epoch_loss / len(train_loader)
            if avg_loss < 0.01:  # Very low loss
                break
        
        # Evaluation
        model.eval()
        with torch.no_grad():
            val_outputs = model(self.X_val)
            _, predicted = torch.max(val_outputs, 1)
            
            # Convert to CPU for sklearn metrics
            y_true = self.y_val.cpu().numpy()
            y_pred = predicted.cpu().numpy()
            
            accuracy = accuracy_score(y_true, y_pred)
            f1 = f1_score(y_true, y_pred, average='weighted')
        
        return {
            'accuracy': accuracy,
            'f1': f1,
            'final_loss': avg_loss,
            'epochs_trained': epoch + 1
        }
    
    def compute_reward(self, metrics):
        # Weighted combination of metrics
        f1_weight = 0.6
        accuracy_weight = 0.3
        efficiency_weight = 0.1
        
        f1_score = metrics['f1']
        accuracy = metrics['accuracy']
        efficiency = max(0, 1.0 - metrics['epochs_trained'] / self.max_epochs)
        
        reward = (f1_score * f1_weight + 
                 accuracy * accuracy_weight + 
                 efficiency * efficiency_weight)
        
        return reward</code></pre>
                    
                    <h3>Step 4: Define Hyperparameter Space</h3>
                    <pre><code class="language-python">space = HyperparameterSpace(
    agent0_params=['dropout_rate', 'weight_decay'],  # Regularization (Agent 0)
    agent1_params=['hidden_size'],                   # Architecture (Agent 1)  
    agent2_params=['learning_rate', 'batch_size'],   # Training (Agent 2)
    bounds={
        'hidden_size': (64, 512),
        'learning_rate': (1e-4, 1e-2),
        'batch_size': (16, 128),
        'dropout_rate': (0.0, 0.5),
        'weight_decay': (1e-6, 1e-3)
    },
    param_types={
        'hidden_size': int,
        'learning_rate': 'log_uniform',  # Log scale for learning rate
        'batch_size': int,
        'dropout_rate': float,
        'weight_decay': 'log_uniform'    # Log scale for weight decay
    }
)</code></pre>
                    
                    <h3>Step 5: Configure and Run Optimization</h3>
                    <pre><code class="language-python"># Create environment
environment = NeuralNetEnvironment(max_epochs=30)

# Load data first
data_info = environment.load_data()
print(f"Dataset loaded: {data_info}")

# Configure optimization
config = DefaultConfigs.standard()
config.update(
    max_steps=50,        # Run 50 optimization steps
    use_cuda=torch.cuda.is_available(),
    verbose=True,
    early_stop_patience=10
)

# Create and run optimizer
optimizer = MAT_HPO_Optimizer(
    environment=environment,
    hyperparameter_space=space,
    config=config,
    output_dir="./nn_optimization_results"
)

print("üöÄ Starting optimization...")
results = optimizer.optimize()

# Display results
print("\n" + "="*50)
print("üéâ OPTIMIZATION COMPLETE!")
print("="*50)
print(f"Best F1 Score: {results['best_performance']['f1']:.4f}")
print(f"Best Accuracy: {results['best_performance']['accuracy']:.4f}")
print(f"Total Steps: {results['optimization_stats']['total_steps']}")
print(f"Total Time: {results['optimization_stats']['total_time']:.2f} seconds")

print("\nüéØ Best Hyperparameters:")
for param, value in results['best_hyperparameters'].items():
    print(f"  {param}: {value}")

print(f"\nüíæ Results saved to: ./nn_optimization_results/")</code></pre>
                </section>
                
                <!-- Configuration Options -->
                <section>
                    <h2>‚öôÔ∏è Configuration Options</h2>
                    <p>MAT-HPO provides several pre-configured optimization settings:</p>
                    
                    <h3>Quick Configuration Presets</h3>
                    <pre><code class="language-python">from MAT_HPO_LIB.utils.config import DefaultConfigs

# Quick test (10 steps) - for debugging
config = DefaultConfigs.quick_test()

# Standard optimization (100 steps) - recommended for most use cases
config = DefaultConfigs.standard()

# Extensive search (500 steps) - for thorough optimization
config = DefaultConfigs.extensive()

# CPU-only optimization (no CUDA)
config = DefaultConfigs.cpu_only()</code></pre>
                    
                    <h3>Custom Configuration</h3>
                    <pre><code class="language-python">from MAT_HPO_LIB.utils.config import OptimizationConfig

config = OptimizationConfig(
    # Core settings
    max_steps=100,                    # Number of optimization steps
    replay_buffer_size=1000,          # Experience replay buffer size
    batch_size=32,                    # SQDDPG batch size
    
    # Learning rates
    policy_learning_rate=1e-4,        # Policy network learning rate
    value_learning_rate=1e-3,         # Value network learning rate
    
    # Device settings
    use_cuda=True,                    # Enable GPU acceleration
    gpu_device=0,                     # GPU device ID
    
    # Early stopping
    early_stop_patience=20,           # Stop if no improvement for N steps
    early_stop_threshold=1e-4,        # Minimum improvement threshold
    
    # Logging and saving
    verbose=True,                     # Print progress information
    save_interval=10,                 # Save models every N steps
    
    # Advanced settings
    gradient_clip=1.0,                # Gradient clipping norm
    target_update_tau=0.005,          # Target network update rate
    noise_std=0.1                     # Exploration noise standard deviation
)</code></pre>
                </section>
                
                <!-- Next Steps -->
                <section>
                    <h2>üéØ Next Steps</h2>
                    <div class="grid grid-2">
                        <div class="card">
                            <h4>üìö Learn More</h4>
                            <p>Dive deeper into MAT-HPO concepts and advanced features:</p>
                            <ul>
                                <li><a href="architecture.html">Understanding the Architecture</a></li>
                                <li><a href="multi-agent.html">Multi-Agent System Details</a></li>
                                <li><a href="environments.html">Creating Custom Environments</a></li>
                            </ul>
                        </div>
                        
                        <div class="card">
                            <h4>üé® Explore Examples</h4>
                            <p>Check out real-world examples for different domains:</p>
                            <ul>
                                <li><a href="examples/image-classification.html">Computer Vision</a></li>
                                <li><a href="examples/nlp.html">Natural Language Processing</a></li>
                                <li><a href="examples/time-series.html">Time Series Analysis</a></li>
                            </ul>
                        </div>
                    </div>
                </section>
                
                <!-- Troubleshooting -->
                <section>
                    <h2>üîß Quick Troubleshooting</h2>
                    
                    <div class="alert alert-warning">
                        <h4>Common Issues & Solutions</h4>
                    </div>
                    
                    <h3>CUDA Out of Memory</h3>
                    <pre><code class="language-python"># Solution: Reduce batch size or use CPU
config = OptimizationConfig(
    use_cuda=False,  # Use CPU instead
    # OR reduce batch size in hyperparameter space
)</code></pre>
                    
                    <h3>Import Errors</h3>
                    <pre><code class="language-bash"># Make sure you're in the right environment
pip list | grep mat-hpo-lib

# Or add to Python path
export PYTHONPATH="${PYTHONPATH}:/path/to/MAT_HPO_LIB"</code></pre>
                    
                    <h3>Slow Performance</h3>
                    <pre><code class="language-python"># Tips for faster optimization:
config = OptimizationConfig(
    max_steps=20,        # Start with fewer steps
    use_cuda=True,       # Use GPU if available
    batch_size=64        # Larger batches can be more efficient
)

# Also consider using quick_test config for debugging</code></pre>
                    
                    <p>For more detailed troubleshooting, see our <a href="troubleshooting.html">Troubleshooting Guide</a> or <a href="faq.html">FAQ</a>.</p>
                </section>
            </div>
        </main>
    </div>
    
    <script src="js/main.js"></script>
</body>
</html>