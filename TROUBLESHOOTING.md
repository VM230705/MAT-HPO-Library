# MAT-HPO Library - Troubleshooting Guide

å®Œæ•´çš„å•é¡Œè¨ºæ–·å’Œè§£æ±ºæ–¹æ¡ˆæŒ‡å—ã€‚

## ç›®éŒ„

- [å¸¸è¦‹å•é¡Œå¿«é€Ÿä¿®å¾©](#-å¸¸è¦‹å•é¡Œå¿«é€Ÿä¿®å¾©)
- [å®‰è£å•é¡Œ](#-å®‰è£å•é¡Œ)
- [é‹è¡Œæ™‚éŒ¯èª¤](#-é‹è¡Œæ™‚éŒ¯èª¤)
- [æ€§èƒ½å•é¡Œ](#-æ€§èƒ½å•é¡Œ)
- [LLM ç›¸é—œå•é¡Œ](#-llm-ç›¸é—œå•é¡Œ)
- [è¨˜æ†¶é«”å•é¡Œ](#-è¨˜æ†¶é«”å•é¡Œ)
- [é…ç½®å•é¡Œ](#-é…ç½®å•é¡Œ)
- [èª¿è©¦æŠ€å·§](#-èª¿è©¦æŠ€å·§)

## å¸¸è¦‹å•é¡Œå¿«é€Ÿä¿®å¾©

| å•é¡Œ | ç—‡ç‹€ | è§£æ±ºæ–¹æ¡ˆ | å‘½ä»¤ |
|------|------|----------|------|
| **âŒ å°å…¥éŒ¯èª¤** | `ModuleNotFoundError: No module named 'MAT_HPO_LIB'` | è¨­ç½® Python è·¯å¾‘ | `export PYTHONPATH=$PYTHONPATH:$(pwd)` |
| **ğŸš« CUDA è¨˜æ†¶é«”ä¸è¶³** | `RuntimeError: CUDA out of memory` | ä½¿ç”¨ CPU æ¨¡å¼ | `config = DefaultConfigs.cpu_only()` |
| **ğŸ” æ¸¬è©¦å®‰è£** | ä¸ç¢ºå®šæ˜¯å¦å®‰è£æ­£ç¢º | é‹è¡ŒåŠŸèƒ½æ¸¬è©¦ | `python test_working_examples.py` |
| **ğŸ“¦ ç¼ºå°‘ä¾è³´** | `ImportError: No module named 'torch'` | å®‰è£ä¾è³´ | `pip install torch numpy scikit-learn` |
| **ğŸ Python ç‰ˆæœ¬** | `SyntaxError` æˆ–ç‰ˆæœ¬éŒ¯èª¤ | æª¢æŸ¥ Python ç‰ˆæœ¬ | `python --version` (éœ€è¦ 3.8+) |

## å®‰è£å•é¡Œ

### å•é¡Œ 1: ModuleNotFoundError

**éŒ¯èª¤è¨Šæ¯**:
```
ModuleNotFoundError: No module named 'MAT_HPO_LIB'
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æª¢æŸ¥ç•¶å‰ç›®éŒ„**:
```bash
pwd
# æ‡‰è©²åœ¨ MAT_HPO_Library ç›®éŒ„ä¸­
```

2. **è¨­ç½® Python è·¯å¾‘**:
```bash
# æ–¹æ³• 1: ç’°å¢ƒè®Šæ•¸
export PYTHONPATH=$PYTHONPATH:$(pwd)

# æ–¹æ³• 2: åœ¨ Python ä¸­è¨­ç½®
import sys
sys.path.append('/path/to/MAT_HPO_Library')
```

3. **é©—è­‰å®‰è£**:
```bash
python -c "from MAT_HPO_LIB import EasyHPO; print('âœ… å®‰è£æˆåŠŸ')"
```

### å•é¡Œ 2: ä¾è³´å®‰è£å¤±æ•—

**éŒ¯èª¤è¨Šæ¯**:
```
ERROR: Could not find a version that satisfies the requirement torch
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æ›´æ–° pip**:
```bash
pip install --upgrade pip
```

2. **å®‰è£ PyTorch**:
```bash
# CPU ç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# GPU ç‰ˆæœ¬ (CUDA 11.8)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

3. **å®‰è£å…¶ä»–ä¾è³´**:
```bash
pip install numpy scikit-learn pandas matplotlib seaborn
```

### å•é¡Œ 3: æ¬Šé™éŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯**:
```
PermissionError: [Errno 13] Permission denied
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **ä½¿ç”¨ç”¨æˆ¶å®‰è£**:
```bash
pip install --user torch numpy scikit-learn
```

2. **å‰µå»ºè™›æ“¬ç’°å¢ƒ**:
```bash
python -m venv mat_hpo_env
source mat_hpo_env/bin/activate  # Linux/Mac
# æˆ–
mat_hpo_env\Scripts\activate     # Windows
pip install torch numpy scikit-learn
```

## ğŸš¨ é‹è¡Œæ™‚éŒ¯èª¤

### å•é¡Œ 1: CUDA ç›¸é—œéŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯**:
```
RuntimeError: CUDA out of memory
RuntimeError: CUDA error: no kernel image is available for execution
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æª¢æŸ¥ CUDA å¯ç”¨æ€§**:
```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"GPU count: {torch.cuda.device_count()}")
```

2. **ä½¿ç”¨ CPU æ¨¡å¼**:
```python
from MAT_HPO_LIB.utils import DefaultConfigs
config = DefaultConfigs.cpu_only()
```

3. **æ¸›å°‘æ‰¹æ¬¡å¤§å°**:
```python
config = OptimizationConfig(
    max_steps=50,
    batch_size=8,  # æ¸›å°‘æ‰¹æ¬¡å¤§å°
    use_cuda=False  # å¼·åˆ¶ä½¿ç”¨ CPU
)
```

### å•é¡Œ 2: æ•¸æ“šæ ¼å¼éŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯**:
```
ValueError: Expected 2D array, got 1D array instead
TypeError: 'NoneType' object is not iterable
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æª¢æŸ¥æ•¸æ“šæ ¼å¼**:
```python
print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_train type: {type(X_train)}")
print(f"y_train type: {type(y_train)}")
```

2. **ç¢ºä¿æ•¸æ“šæ­£ç¢ºæ ¼å¼**:
```python
import numpy as np

# ç¢ºä¿æ˜¯ numpy æ•¸çµ„
X_train = np.array(X_train)
y_train = np.array(y_train)

# æª¢æŸ¥ç¶­åº¦
if len(X_train.shape) == 1:
    X_train = X_train.reshape(-1, 1)
```

3. **æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§**:
```python
# æª¢æŸ¥æ˜¯å¦æœ‰ NaN å€¼
print(f"X_train NaN count: {np.isnan(X_train).sum()}")
print(f"y_train NaN count: {np.isnan(y_train).sum()}")

# æª¢æŸ¥æ˜¯å¦æœ‰ç„¡é™å€¼
print(f"X_train inf count: {np.isinf(X_train).sum()}")
```

### å•é¡Œ 3: è¶…åƒæ•¸ç©ºé–“éŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯**:
```
ValueError: Invalid hyperparameter space configuration
KeyError: 'learning_rate'
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æª¢æŸ¥è¶…åƒæ•¸ç©ºé–“å®šç¾©**:
```python
from MAT_HPO_LIB.core.hyperparameter_space import HyperparameterSpace

space = HyperparameterSpace()

# æ­£ç¢ºçš„å®šç¾©æ–¹å¼
space.add_continuous('learning_rate', min_val=1e-5, max_val=1e-1, agent=0)
space.add_discrete('batch_size', choices=[16, 32, 64, 128], agent=1)
space.add_boolean('use_dropout', agent=2)

# æª¢æŸ¥ç©ºé–“
print(f"Space parameters: {space.get_parameter_names()}")
```

2. **ç¢ºä¿åƒæ•¸åç¨±ä¸€è‡´**:
```python
# åœ¨ç’°å¢ƒä¸­ä½¿ç”¨ç›¸åŒçš„åƒæ•¸åç¨±
def create_model(self, hyperparams):
    return MyModel(
        learning_rate=hyperparams['learning_rate'],  # å¿…é ˆèˆ‡ç©ºé–“å®šç¾©ä¸€è‡´
        batch_size=hyperparams['batch_size'],
        use_dropout=hyperparams['use_dropout']
    )
```

## æ€§èƒ½å•é¡Œ

### å•é¡Œ 1: å„ªåŒ–é€Ÿåº¦å¤ªæ…¢

**ç—‡ç‹€**: æ¯å€‹æ­¥é©Ÿè€—æ™‚éé•·

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æ¸›å°‘å„ªåŒ–æ­¥æ•¸**:
```python
config = OptimizationConfig(
    max_steps=20,  # æ¸›å°‘æ­¥æ•¸
    batch_size=16,  # æ¸›å°‘æ‰¹æ¬¡å¤§å°
    behaviour_update_freq=5  # æ¸›å°‘æ›´æ–°é »ç‡
)
```

2. **ä½¿ç”¨å¿«é€Ÿæ¸¬è©¦é…ç½®**:
```python
from MAT_HPO_LIB.utils import DefaultConfigs
config = DefaultConfigs.quick_test()  # åªæœ‰ 10 æ­¥
```

3. **ç¦ç”¨è©³ç´°æ—¥èªŒ**:
```python
config = OptimizationConfig(
    max_steps=50,
    verbose=False,  # ç¦ç”¨è©³ç´°è¼¸å‡º
    log_level="WARNING"
)
```

### å•é¡Œ 2: è¨˜æ†¶é«”ä½¿ç”¨éé«˜

**ç—‡ç‹€**: ç³»çµ±è¨˜æ†¶é«”ä¸è¶³æˆ– GPU è¨˜æ†¶é«”ä¸è¶³

**è§£æ±ºæ–¹æ¡ˆ**:

1. **ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨**:
```python
import psutil
import torch

# CPU è¨˜æ†¶é«”
memory = psutil.virtual_memory()
print(f"CPU Memory: {memory.percent}% used")

# GPU è¨˜æ†¶é«”
if torch.cuda.is_available():
    print(f"GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f} GB")
    print(f"GPU Memory Max: {torch.cuda.max_memory_allocated()/1024**3:.2f} GB")
```

2. **å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨**:
```python
config = OptimizationConfig(
    max_steps=30,
    batch_size=8,  # æ¸›å°‘æ‰¹æ¬¡å¤§å°
    use_cuda=False,  # ä½¿ç”¨ CPU
    gradient_clip=0.5  # æ¢¯åº¦è£å‰ª
)
```

3. **æ¸…ç†è¨˜æ†¶é«”**:
```python
import gc
import torch

# æ¸…ç† Python è¨˜æ†¶é«”
gc.collect()

# æ¸…ç† GPU è¨˜æ†¶é«”
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
```

## ğŸ¤– LLM ç›¸é—œå•é¡Œ

### å•é¡Œ 1: LLM é€£æ¥å¤±æ•—

**éŒ¯èª¤è¨Šæ¯**:
```
ConnectionError: Failed to connect to LLM service
TimeoutError: LLM request timed out
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æª¢æŸ¥ Ollama æœå‹™**:
```bash
# æª¢æŸ¥ Ollama æ˜¯å¦é‹è¡Œ
curl http://localhost:11434/api/tags

# å•Ÿå‹• Ollama æœå‹™
ollama serve
```

2. **æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§**:
```bash
# åˆ—å‡ºå¯ç”¨æ¨¡å‹
ollama list

# æ‹‰å–æ‰€éœ€æ¨¡å‹
ollama pull llama3.2:3b
```

3. **ä½¿ç”¨å‚™ç”¨ LLM é…ç½®**:
```python
optimizer = EasyHPO(
    task_type="classification",
    llm_enabled=True,
    llm_model="llama3.2:1b",  # ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
    llm_timeout=30  # å¢åŠ è¶…æ™‚æ™‚é–“
)
```

### å•é¡Œ 2: LLM å›æ‡‰æ ¼å¼éŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯**:
```
ValueError: Invalid LLM response format
JSONDecodeError: Expecting value
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æª¢æŸ¥ LLM å›æ‡‰**:
```python
from MAT_HPO_LIB.llm import OllamaLLMClient

client = OllamaLLMClient("llama3.2:3b")
response = client.generate_response("Test prompt")
print(f"LLM Response: {response}")
```

2. **ä½¿ç”¨æ›´ç©©å®šçš„æ¨¡å‹**:
```python
optimizer = EasyHPO(
    task_type="classification",
    llm_enabled=True,
    llm_model="llama3.2:1b",  # æ›´ç©©å®šçš„æ¨¡å‹
    llm_strategy="fixed_alpha"  # ä½¿ç”¨å›ºå®šç­–ç•¥
)
```

3. **ç¦ç”¨ LLM é€²è¡Œæ¸¬è©¦**:
```python
optimizer = EasyHPO(
    task_type="classification",
    llm_enabled=False  # æš«æ™‚ç¦ç”¨ LLM
)
```

## ğŸ’¾ è¨˜æ†¶é«”å•é¡Œ

### å•é¡Œ 1: è¨˜æ†¶é«”æ´©æ¼

**ç—‡ç‹€**: è¨˜æ†¶é«”ä½¿ç”¨æŒçºŒå¢é•·

**è§£æ±ºæ–¹æ¡ˆ**:

1. **å®šæœŸæ¸…ç†è¨˜æ†¶é«”**:
```python
import gc
import torch

def cleanup_memory():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

# åœ¨å„ªåŒ–éç¨‹ä¸­å®šæœŸèª¿ç”¨
for step in range(max_steps):
    # å„ªåŒ–æ­¥é©Ÿ
    optimizer.step()
    
    # æ¯ 10 æ­¥æ¸…ç†ä¸€æ¬¡
    if step % 10 == 0:
        cleanup_memory()
```

2. **ä½¿ç”¨è¨˜æ†¶é«”ç›£æ§**:
```python
from MAT_HPO_LIB.utils import MemoryMonitor

monitor = MemoryMonitor()
config = OptimizationConfig(
    max_steps=100,
    memory_monitor=monitor
)
```

### å•é¡Œ 2: å¤§æ•¸æ“šé›†è™•ç†

**ç—‡ç‹€**: æ•¸æ“šé›†å¤ªå¤§ç„¡æ³•è¼‰å…¥

**è§£æ±ºæ–¹æ¡ˆ**:

1. **ä½¿ç”¨æ•¸æ“šç”Ÿæˆå™¨**:
```python
class DataGenerator:
    def __init__(self, X, y, batch_size=1000):
        self.X = X
        self.y = y
        self.batch_size = batch_size
        self.current_idx = 0
    
    def get_batch(self):
        start = self.current_idx
        end = min(start + self.batch_size, len(self.X))
        batch_X = self.X[start:end]
        batch_y = self.y[start:end]
        self.current_idx = end
        return batch_X, batch_y
```

2. **åˆ†æ‰¹è™•ç†**:
```python
def process_large_dataset(X, y, batch_size=1000):
    results = []
    for i in range(0, len(X), batch_size):
        batch_X = X[i:i+batch_size]
        batch_y = y[i:i+batch_size]
        # è™•ç†æ‰¹æ¬¡
        result = process_batch(batch_X, batch_y)
        results.append(result)
    return results
```

## âš™ï¸ é…ç½®å•é¡Œ

### å•é¡Œ 1: é…ç½®åƒæ•¸ç„¡æ•ˆ

**éŒ¯èª¤è¨Šæ¯**:
```
ValueError: Invalid configuration parameter
TypeError: Unexpected keyword argument
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æª¢æŸ¥é…ç½®åƒæ•¸**:
```python
from MAT_HPO_LIB.utils import OptimizationConfig

# æ­£ç¢ºçš„é…ç½®
config = OptimizationConfig(
    max_steps=100,        # æ•´æ•¸
    batch_size=32,        # æ•´æ•¸
    use_cuda=True,        # å¸ƒæ—å€¼
    learning_rate=1e-3,   # æµ®é»æ•¸
    exploration_rate=0.1  # 0-1 ä¹‹é–“çš„æµ®é»æ•¸
)

# æª¢æŸ¥é…ç½®
print(f"Config: {config}")
```

2. **ä½¿ç”¨é è¨­é…ç½®**:
```python
from MAT_HPO_LIB.utils import DefaultConfigs

# ä½¿ç”¨é è¨­é…ç½®
config = DefaultConfigs.standard()
```

### å•é¡Œ 2: ç’°å¢ƒé…ç½®éŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯**:
```
AttributeError: 'MyEnvironment' object has no attribute 'load_data'
NotImplementedError: Abstract method not implemented
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æª¢æŸ¥ç’°å¢ƒå¯¦ç¾**:
```python
from MAT_HPO_LIB import BaseEnvironment

class MyEnvironment(BaseEnvironment):
    def load_data(self):
        # å¿…é ˆå¯¦ç¾
        return {'train_X': X_train, 'train_Y': y_train}
    
    def create_model(self, hyperparams):
        # å¿…é ˆå¯¦ç¾
        return MyModel(**hyperparams)
    
    def train_evaluate(self, model, hyperparams):
        # å¿…é ˆå¯¦ç¾
        return {'f1': 0.85}
    
    def compute_reward(self, metrics):
        # å¿…é ˆå¯¦ç¾
        return metrics['f1']
```

2. **ä½¿ç”¨é å»ºç’°å¢ƒ**:
```python
from MAT_HPO_LIB.core.enhanced_environment import TimeSeriesEnvironment

# ä½¿ç”¨é å»ºçš„ç’°å¢ƒ
environment = TimeSeriesEnvironment("MyDataset")
```

## ğŸ” èª¿è©¦æŠ€å·§

### 1. å•Ÿç”¨è©³ç´°æ—¥èªŒ

```python
import logging

# è¨­ç½®æ—¥èªŒç´šåˆ¥
logging.basicConfig(level=logging.DEBUG)

# åœ¨é…ç½®ä¸­å•Ÿç”¨è©³ç´°è¼¸å‡º
config = OptimizationConfig(
    max_steps=10,
    verbose=True,
    log_level="DEBUG"
)
```

### 2. ä½¿ç”¨æ¸¬è©¦æ¨¡å¼

```python
# ä½¿ç”¨å¿«é€Ÿæ¸¬è©¦é…ç½®
config = DefaultConfigs.quick_test()

# æ¸›å°‘æ•¸æ“šå¤§å°é€²è¡Œæ¸¬è©¦
X_train_small = X_train[:100]
y_train_small = y_train[:100]
```

### 3. æª¢æŸ¥ä¸­é–“çµæœ

```python
# åœ¨ç’°å¢ƒä¸­æ·»åŠ èª¿è©¦è¼¸å‡º
def train_evaluate(self, model, hyperparams):
    print(f"Training with hyperparams: {hyperparams}")
    
    # è¨“ç·´é‚è¼¯
    metrics = train_and_evaluate(model, hyperparams)
    
    print(f"Training completed. Metrics: {metrics}")
    return metrics
```

### 4. ä½¿ç”¨æ–·é»èª¿è©¦

```python
import pdb

def train_evaluate(self, model, hyperparams):
    pdb.set_trace()  # è¨­ç½®æ–·é»
    # åœ¨é€™è£¡å¯ä»¥æª¢æŸ¥è®Šæ•¸ç‹€æ…‹
    metrics = train_and_evaluate(model, hyperparams)
    return metrics
```

## ğŸ“ ç²å–å¹«åŠ©

å¦‚æœä»¥ä¸Šè§£æ±ºæ–¹æ¡ˆéƒ½ç„¡æ³•è§£æ±ºæ‚¨çš„å•é¡Œï¼š

1. **æª¢æŸ¥ GitHub Issues**: [MAT-HPO-Library Issues](https://github.com/VM230705/MAT-HPO-Library/issues)
2. **å‰µå»ºæ–°çš„ Issue**: æä¾›è©³ç´°çš„éŒ¯èª¤è¨Šæ¯å’Œç’°å¢ƒä¿¡æ¯
3. **æŸ¥çœ‹æ–‡æª”**: [å®Œæ•´æ–‡æª”](https://vm230705.github.io/MAT-HPO-Library/)
4. **ç¤¾å€è¨è«–**: [GitHub Discussions](https://github.com/VM230705/MAT-HPO-Library/discussions)

### å ±å‘Šå•é¡Œæ™‚è«‹åŒ…å«ï¼š

- Python ç‰ˆæœ¬
- æ“ä½œç³»çµ±
- éŒ¯èª¤çš„å®Œæ•´å †ç–Šè¿½è¹¤
- ä½¿ç”¨çš„é…ç½®åƒæ•¸
- æ•¸æ“šé›†å¤§å°å’Œé¡å‹
- æ˜¯å¦ä½¿ç”¨ GPU

---

**è¨˜ä½**: å¤§å¤šæ•¸å•é¡Œéƒ½å¯ä»¥é€šéä½¿ç”¨é è¨­é…ç½®å’Œæ¸›å°‘æ•¸æ“šå¤§å°ä¾†å¿«é€Ÿè¨ºæ–·å’Œè§£æ±ºï¼ ğŸš€