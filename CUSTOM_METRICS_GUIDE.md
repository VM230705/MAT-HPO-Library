# MAT-HPO Library - Custom Metrics Guide

## è¨­è¨ˆç†å¿µ

MAT-HPO-Libraryæä¾›**é€šç”¨æ¥å£**ï¼Œè®“ä½¿ç”¨è€…å¯ä»¥é€éåƒæ•¸å‚³å…¥è‡ªè¨‚çš„metricså’Œrewardè¨­è¨ˆï¼Œ**è€Œä¸éœ€è¦ä¿®æ”¹åº«æœ¬èº«çš„ä»£ç¢¼**ã€‚

## é€šç”¨æ¥å£æ¦‚è¦½

### 1. **BaseEnvironment è‡ªè¨‚åƒæ•¸**

```python
class MyEnvironment(BaseEnvironment):
    def __init__(self, ...):
        super().__init__(
            name="MyEnvironment",
            # ğŸ¯ è‡ªè¨‚metricsåˆ—è¡¨
            custom_metrics=['train_loss', 'val_loss', 'mase', 'smape', 'mae', 'rmse'],
            
            # ğŸ“Š Metricåç¨±æ˜ å°„ï¼ˆç”¨æ–¼é¡¯ç¤ºï¼‰
            metric_names_mapping={
                'f1': 'SMAPE',    # F1é¡¯ç¤ºç‚ºSMAPE
                'auc': 'MAE',     # AUCé¡¯ç¤ºç‚ºMAE
                'gmean': 'RMSE'   # G-meané¡¯ç¤ºç‚ºRMSE
            },
            
            # ğŸ è‡ªè¨‚rewardå‡½æ•¸
            reward_function=my_custom_reward_function
        )
```

### 2. **HPOLogger è‡ªè¨‚åƒæ•¸**

```python
from MAT_HPO_LIB.utils.logger import HPOLogger

# å®šç¾©metricsæå–å™¨
def extract_timeseries_metrics(hyperparams: dict) -> dict:
    """å¾hyperparamsä¸­æå–è¦è¨˜éŒ„çš„æŒ‡æ¨™"""
    return {
        'train_loss': float(hyperparams.get('train_loss', 0.0)),
        'val_loss': float(hyperparams.get('val_loss', 0.0)),
        'mase': float(hyperparams.get('mase', 1.0)),
        'smape': float(hyperparams.get('original_smape', 0.0)),
        'mae': float(hyperparams.get('original_mae', 0.0)),
        'rmse': float(hyperparams.get('original_rmse', 0.0)),
    }

# å‰µå»ºè‡ªè¨‚logger
logger = HPOLogger(
    output_dir='./results',
    metric_names={'f1': 'SMAPE', 'auc': 'MAE', 'gmean': 'RMSE'},
    custom_metrics=['train_loss', 'val_loss', 'mase', 'smape', 'mae', 'rmse'],
    metrics_extractor=extract_timeseries_metrics
)
```

## ğŸš€ å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

### **æ™‚é–“åºåˆ—é æ¸¬å ´æ™¯**

```python
#!/usr/bin/env python3
import numpy as np
from MAT_HPO_LIB import MAT_HPO_Optimizer, BaseEnvironment, HyperparameterSpace
from MAT_HPO_LIB.utils.logger import HPOLogger

# ============================================================================
# 1. å®šç¾©è‡ªè¨‚rewardå‡½æ•¸
# ============================================================================

def timeseries_reward(metrics: dict) -> float:
    """åŸºæ–¼è¨“ç·´æå¤±è¨ˆç®—rewardï¼ˆé¿å…data leakageï¼‰"""
    train_loss = metrics.get('train_loss', 1.0)
    if train_loss <= 0:
        train_loss = 1.0
    
    # è½‰æ›ç‚ºrewardï¼ˆè¶Šå°çš„lossè¶Šé«˜çš„rewardï¼‰
    reward = -np.log(max(train_loss, 1e-6))
    reward = max(0.1, min(10.0, reward))
    
    # æ˜ å°„åˆ°0-1ç¯„åœ
    reward = max(0.05, min(0.9, reward / 10.0))
    return reward

# ============================================================================
# 2. å®šç¾©metricsæå–å™¨
# ============================================================================

def extract_metrics(hyperparams: dict) -> dict:
    """å¾hyperparamsæå–æ‰€æœ‰è¦è¨˜éŒ„çš„åŸå§‹æŒ‡æ¨™"""
    metrics = {
        'train_loss': float(hyperparams.get('train_loss', 0.0)),
        'mase': float(hyperparams.get('mase', 0.0)),
        'smape': float(hyperparams.get('original_smape', 0.0)),
        'mae': float(hyperparams.get('original_mae', 0.0)),
        'rmse': float(hyperparams.get('original_rmse', 0.0)),
    }
    
    # å¯é¸çš„validationæŒ‡æ¨™
    if 'val_loss' in hyperparams:
        metrics['val_loss'] = float(hyperparams['val_loss'])
    if 'overfitting_ratio' in hyperparams:
        metrics['overfitting_ratio'] = float(hyperparams['overfitting_ratio'])
    
    return metrics

# ============================================================================
# 3. å‰µå»ºç’°å¢ƒï¼ˆä½¿ç”¨è‡ªè¨‚é…ç½®ï¼‰
# ============================================================================

class TimeSeriesEnvironment(BaseEnvironment):
    def __init__(self, model_name, dataset_name):
        super().__init__(
            name=f"TS-{model_name}-{dataset_name}",
            custom_metrics=['train_loss', 'val_loss', 'mase', 'smape', 'mae', 'rmse'],
            metric_names_mapping={'f1': 'SMAPE', 'auc': 'MAE', 'gmean': 'RMSE'},
            reward_function=timeseries_reward
        )
        self.model_name = model_name
        self.dataset_name = dataset_name
    
    def load_data(self):
        # è¼‰å…¥æ™‚é–“åºåˆ—æ•¸æ“š
        pass
    
    def create_model(self, hyperparams):
        # å‰µå»ºæ¨¡å‹
        pass
    
    def train_evaluate(self, model, hyperparams):
        # è¨“ç·´æ¨¡å‹...
        train_loss = 331.72  # ç¤ºä¾‹å€¼
        val_loss = 346.51
        
        # è©•ä¼°æ¨¡å‹...
        mase = 2.304
        mae = 632.53
        rmse = 809.25
        smape = 0.0618
        
        # è¿”å›æ‰€æœ‰æŒ‡æ¨™
        return {
            # åŸå§‹è¨“ç·´æŒ‡æ¨™
            'train_loss': train_loss,
            'val_loss': val_loss,
            'overfitting_ratio': val_loss / train_loss,
            
            # åŸå§‹æ¸¬è©¦é›†æŒ‡æ¨™
            'mase': mase,
            'smape': smape,
            'mae': mae,
            'rmse': rmse,
            'mse': rmse ** 2,
            
            # è½‰æ›å¾Œçš„å€¼ï¼ˆçµ¦MAT-HPOå„ªåŒ–ç”¨ï¼‰
            # å°‡"è¶Šå°è¶Šå¥½"çš„æŒ‡æ¨™è½‰æ›ç‚º"è¶Šå¤§è¶Šå¥½"
            'f1': 0.8 - min(0.8, smape / 2.0),
            'auc': 0.8 - min(0.8, mae / 1000.0),
            'gmean': 0.8 - min(0.8, rmse / 1000.0),
            
            # ä¿å­˜åŸå§‹å€¼ï¼ˆä½¿ç”¨original_å‰ç¶´ï¼‰
            'original_smape': smape,
            'original_mae': mae,
            'original_rmse': rmse
        }
    
    def compute_reward(self, metrics):
        # ä½¿ç”¨è‡ªè¨‚rewardå‡½æ•¸
        if self.custom_reward_function:
            return self.custom_reward_function(metrics)
        else:
            return timeseries_reward(metrics)

# ============================================================================
# 4. è¨­ç½®optimizerå’Œlogger
# ============================================================================

def run_optimization():
    # å‰µå»ºç’°å¢ƒ
    env = TimeSeriesEnvironment("dlinear", "us_births")
    
    # å‰µå»ºhyperparameter space
    space = HyperparameterSpace()
    space.add_continuous('learning_rate', 1e-5, 1e-2, agent=0)
    space.add_discrete('batch_size', [8, 16, 32, 64], agent=0)
    space.add_discrete('epochs', [20, 50, 100], agent=0)
    
    # å‰µå»ºé…ç½®
    config = DefaultConfigs.standard()
    config.max_steps = 10
    
    # å‰µå»ºè‡ªè¨‚logger
    logger = HPOLogger(
        output_dir='./timeseries_results',
        metric_names={'f1': 'SMAPE', 'auc': 'MAE', 'gmean': 'RMSE'},
        custom_metrics=['train_loss', 'val_loss', 'mase', 'smape', 'mae', 'rmse'],
        metrics_extractor=extract_metrics  # ä½¿ç”¨è‡ªè¨‚æå–å™¨
    )
    
    # å‰µå»ºoptimizer
    optimizer = MAT_HPO_Optimizer(env, space, config)
    optimizer.logger = logger  # è¨­ç½®è‡ªè¨‚logger
    
    # é‹è¡Œå„ªåŒ–
    results = optimizer.optimize()
    
    return results

if __name__ == "__main__":
    results = run_optimization()
    print(f"\nâœ… æœ€ä½³reward: {results['best_performance']['reward']:.4f}")
```

## è¼¸å‡ºæ ¼å¼

### **step_log.jsonl æ ¼å¼**

ä½¿ç”¨è‡ªè¨‚metrics extractorå¾Œï¼Œæ¯å€‹æ­¥é©Ÿæœƒè¨˜éŒ„ï¼š

```json
{
  "step": 0,
  "timestamp": "2025-10-01T08:00:00",
  "metrics": {
    "train_loss": 331.72,
    "val_loss": 346.51,
    "overfitting_ratio": 1.045,
    "mase": 2.304,
    "smape": 0.0618,
    "mae": 632.53,
    "rmse": 809.25,
    "mse": 654889.81,
    "f1_transformed": 0.7691,
    "auc_transformed": 0.1675,
    "gmean_transformed": 0.1000
  },
  "timing": {...},
  "hyperparameters": {...}
}
```

## âœ… å„ªé»

1. **âœ… ä¸éœ€è¦ä¿®æ”¹MAT-HPO-Libraryä»£ç¢¼** - é€šéåƒæ•¸é…ç½®
2. **âœ… å®Œå…¨è‡ªè¨‚metrics** - è¿½è¹¤ä»»ä½•æƒ³è¦çš„æŒ‡æ¨™
3. **âœ… è‡ªè¨‚rewardé‚è¼¯** - éˆæ´»å®šç¾©å„ªåŒ–ç›®æ¨™
4. **âœ… ä¿æŒåŸå§‹å€¼** - è¨˜éŒ„æœªç¶“è½‰æ›çš„çœŸå¯¦æ•¸æ“š
5. **âœ… é€šç”¨å¯é‡ç”¨** - é©ç”¨æ–¼ä»»ä½•é ˜åŸŸï¼ˆæ™‚é–“åºåˆ—ã€åˆ†é¡ã€å›æ­¸ç­‰ï¼‰

## ä½¿ç”¨å»ºè­°

1. **å®šç¾©metrics_extractor**: æ˜ç¢ºæŒ‡å®šè¦è¨˜éŒ„å“ªäº›åŸå§‹æŒ‡æ¨™
2. **å®šç¾©reward_function**: æ˜ç¢ºå¦‚ä½•è¨ˆç®—reward
3. **ä½¿ç”¨custom_metrics**: åˆ—å‡ºæ‰€æœ‰è¦è¿½è¹¤çš„æŒ‡æ¨™åç¨±
4. **ä½¿ç”¨metric_names_mapping**: å°‡å…§éƒ¨åç¨±æ˜ å°„åˆ°æ˜“è®€çš„é¡¯ç¤ºåç¨±

é€™æ¨£æ¯æ¬¡ä½¿ç”¨MAT-HPO-Libraryæ™‚ï¼Œåªéœ€è¦åœ¨**è‡ªå·±çš„é …ç›®ä»£ç¢¼ä¸­**å®šç¾©é€™äº›å‡½æ•¸å’Œé…ç½®ï¼Œè€Œä¸éœ€è¦ä¿®æ”¹åº«æœ¬èº«ï¼


